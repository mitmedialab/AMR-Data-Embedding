{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import code_book_embed\n",
    "#ms.use('seaborn-muted')\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reload(code_book_embed)\n",
    "from code_book_embed import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Waveform Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# try each waveform to get individual cross-correlation accuracy\n",
    "def expanded_waveform_optimize(waveform_list):\n",
    "    results_ave_per_source = {}\n",
    "    \n",
    "    #paths_to_source = [\"audio_samples/man2_orig.wav\", \"audio_samples/woman2_orig.wav\"]\n",
    "    base_path = \"/audio_samples/Harvard_Sentences/\"\n",
    "    paths_to_source = [os.getcwd() + base_path + filename for filename in os.listdir(os.getcwd() + base_path)]\n",
    "    \n",
    "    for p in paths_to_source:\n",
    "        print \"Currently processing all waveforms for speech sample: \", p\n",
    "        for w1 in waveform_list:\n",
    "            E2 = Embed(p, [w1], [0], [0])\n",
    "\n",
    "            # Fix the truncation and energy values for generally low perceptibility\n",
    "            E2.truncate(0.4, idx_list=[0])\n",
    "            E2.energy(0.2, idx_list=[0])\n",
    "            E2.pitch_shift(-15, idx_list=[0])\n",
    "\n",
    "            embed2, num_total_digits = E2.get_embedded_audio(plot=False)\n",
    "            d_embed2, sr = compress_and_decompress(embed2, \"compression_samples/\", plot=False)\n",
    "\n",
    "            # get the timeseries of the the original waveforms and recover\n",
    "            wf = E2.get_data_timeseries()\n",
    "            R2 = Recover(d_embed2, wf, [0], [0], num_total_digits)\n",
    "            acc = R2.get_raw_bits_recovered(thres=0.85, plot=False)\n",
    "            \n",
    "            metadata = str(w1).split('/')[-1]\n",
    "            \n",
    "#             print \"------------------\"\n",
    "#             print \"waveform: \", metadata\n",
    "#             print \"full sequence length: \", R2.full_seq_length\n",
    "#             print \"raw acc is: \", acc\n",
    "#             print \"------------------\"\n",
    "\n",
    "            # results metrics average between speech samples\n",
    "            try:\n",
    "                results_ave_per_source[metadata] += (float(acc) / len(paths_to_source))\n",
    "            except KeyError:\n",
    "                results_ave_per_source[metadata] = (float(acc) / len(paths_to_source))\n",
    "                    \n",
    "    return results_ave_per_source\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "base_path = [\"/speech_samples/french/\", \"/speech_samples/angrez/\", \"/speech_samples/mandarin/\", \"/speech_samples/arabic/\",\n",
    "             \"/speech_samples/tamil/\"]\n",
    "waveform_list = []\n",
    "for bp in base_path:\n",
    "    paths_to_source = [os.getcwd() + bp + filename for filename in os.listdir(os.getcwd() + bp)]\n",
    "    waveform_list += paths_to_source\n",
    "\n",
    "results_ave_dict = expanded_waveform_optimize(waveform_list)\n",
    "pickle.dump( results_ave_dict, open( \"multi_language_ave_waveform_fixed_wfs.pkl\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fixed waveforms based on output of above optimization\n",
    "\n",
    "# run the accuracy across all harvard sentence samples and take average\n",
    "def system_accuracy(p, W, pf0, pf1, ef0, ef1, lf):    \n",
    "    W = [w1, w2]\n",
    "    E2 = Embed(p, [w1, w2], [0,1], [0,1,0,1,0])\n",
    "\n",
    "    # Fix the truncation and energy values\n",
    "    E2.truncate(lf, idx_list=[0,1])\n",
    "    E2.energy(ef0, idx_list=[0])\n",
    "    E2.energy(ef1, idx_list=[1])\n",
    "    E2.pitch_shift(pf0, idx_list=[0])\n",
    "    E2.pitch_shift(pf1, idx_list=[1])\n",
    "\n",
    "    embed2, num_total_digits = E2.get_embedded_audio(plot=False)\n",
    "    d_embed2, sr = compress_and_decompress(embed2, \"compression_samples/\", plot=False)\n",
    "\n",
    "    # get the timeseries of the the original waveforms and recover\n",
    "    wf = E2.get_data_timeseries()\n",
    "    R2 = Recover(d_embed2, wf, [0,1], [0,1,0,1,0], num_total_digits)\n",
    "    final_sequence2 = R2.get_bit_sequence(thres=0.85, plot=False)\n",
    "    acc = R2.get_recovery_estimate(final_sequence2, dump=False, conv=False)\n",
    "    \n",
    "    return acc\n",
    "\n",
    "# make p and [w1, w2] global variables\n",
    "def objective(input):\n",
    "    [pf0, pf1, ef0, ef1, lf] = input\n",
    "    # negative because we are trying to maximize\n",
    "    pf0_step = pf0 * -15.0  # multiply by lower bound to feed in as step\n",
    "    pf1_step = pf1 * -15.0 \n",
    "    \n",
    "    if not(pf0 > 0 and pf0 < 1.0) or not(pf1 > 0 and pf1 < 1.0) or not(ef0 > 0.1 and ef0 < 0.5) or    not(ef1 > 0.1 and ef1 < 0.5) or not(lf > 0.1 and lf < 1.0):\n",
    "        #print \"------Out of Bounds------\"\n",
    "        #print \"pf0\", pf0\n",
    "        #print \"pf1\", pf1\n",
    "        #print \"pf0 step\", pf0_step\n",
    "        #print \"pf1 step\", pf1_step\n",
    "        #print \"ef0\", ef0\n",
    "        #print \"ef1\", ef1\n",
    "        #print \"lf\", lf\n",
    "        #print \"-------------------------\"\n",
    "        a_really_high_number = 10000000\n",
    "        return a_really_high_number\n",
    "    \n",
    "    else:\n",
    "        ave_cover_audios = 0\n",
    "        for cover_audio in cover_audio_list:\n",
    "            ave_cover_audios += system_accuracy(cover_audio, [w1, w2], pf0_step, pf1_step, ef0, ef1, lf) / float(len(cover_audio_list))\n",
    "\n",
    "        f1 = sys_weight*(ave_cover_audios)\n",
    "        f2 = p_weight*(pf0 + pf1)\n",
    "        f3 = e_weight*(ef0 + ef1)\n",
    "        f4 = l_weight*(lf)\n",
    "        f = f1 + f2 - f3 - f4\n",
    "        \n",
    "#         print \"----Correct----\"\n",
    "#         print \"f: \", -1.0 * f\n",
    "#         print \"data accuracy: \", f1\n",
    "#         print \"pitch weight: \", f2\n",
    "#         print \"energy weight: \", f3\n",
    "#         print \"pf0 step\", pf0_step\n",
    "#         print \"pf1 step\", pf1_step\n",
    "#         print \"---------------\"\n",
    "        return -1.0 * f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constraints:  [{'fun': <function <lambda> at 0x7f06802a3e60>, 'type': 'ineq'}, {'fun': <function <lambda> at 0x7f06802a3d70>, 'type': 'ineq'}, {'fun': <function <lambda> at 0x7f068013a938>, 'type': 'ineq'}, {'fun': <function <lambda> at 0x7f068013a488>, 'type': 'ineq'}, {'fun': <function <lambda> at 0x7f068013a578>, 'type': 'ineq'}, {'fun': <function <lambda> at 0x7f068013a398>, 'type': 'ineq'}, {'fun': <function <lambda> at 0x7f068013a2a8>, 'type': 'ineq'}, {'fun': <function <lambda> at 0x7f068013aed8>, 'type': 'ineq'}, {'fun': <function <lambda> at 0x7f068013ade8>, 'type': 'ineq'}, {'fun': <function <lambda> at 0x7f068013ad70>, 'type': 'ineq'}]\n",
      "Now processing:  0.7 0.1 0.1 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ishwarya/.local/lib/python2.7/site-packages/scipy/optimize/_minimize.py:394: RuntimeWarning: Method Powell cannot handle constraints nor bounds.\n",
      "  RuntimeWarning)\n",
      "/home/ishwarya/.local/lib/python2.7/site-packages/ipykernel/__main__.py:33: OptimizeWarning: Unknown solver options: fatol, xatol\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: -0.835804\n",
      "         Iterations: 4\n",
      "         Function evaluations: 638\n",
      "   direc: array([[ 1.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  1.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  1.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  1.]])\n",
      "     fun: -0.83580438797425616\n",
      " message: 'Optimization terminated successfully.'\n",
      "    nfev: 638\n",
      "     nit: 4\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([ 1.        ,  1.        ,  0.1       ,  0.1       ,  0.44195611])\n",
      "Now processing:  0.5 0.1 0.3 0.1\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.599322\n",
      "         Iterations: 4\n",
      "         Function evaluations: 646\n",
      "   direc: array([[ 1.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  1.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  1.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  1.]])\n",
      "     fun: -0.59932245041478682\n",
      " message: 'Optimization terminated successfully.'\n",
      "    nfev: 646\n",
      "     nit: 4\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([ 1.        ,  0.99999698,  0.1       ,  0.1       ,  0.40677247])\n",
      "Now processing:  0.3 0.2 0.4 0.1\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.573586\n",
      "         Iterations: 3\n",
      "         Function evaluations: 436\n",
      "   direc: array([[ 1.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  1.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  1.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  1.]])\n",
      "     fun: -0.57358593598663787\n",
      " message: 'Optimization terminated successfully.'\n",
      "    nfev: 436\n",
      "     nit: 3\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([ 0.99999985,  0.99999979,  0.10000378,  0.10000067,  0.46412211])\n",
      "Now processing:  0.3 0.3 0.3 0.1\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.799304\n",
      "         Iterations: 3\n",
      "         Function evaluations: 444\n",
      "   direc: array([[ 1.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  1.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  1.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  1.]])\n",
      "     fun: -0.79930431977096672\n",
      " message: 'Optimization terminated successfully.'\n",
      "    nfev: 444\n",
      "     nit: 3\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([ 0.99999997,  0.99999975,  0.10000003,  0.10000376,  0.40694461])\n",
      "Now processing:  0.1 0.4 0.1 0.4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.793253\n",
      "         Iterations: 5\n",
      "         Function evaluations: 964\n",
      "   direc: array([[ 1.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  1.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  1.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  1.]])\n",
      "     fun: -0.79325279241478841\n",
      " message: 'Optimization terminated successfully.'\n",
      "    nfev: 964\n",
      "     nit: 5\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([ 0.99877707,  0.99951697,  0.1       ,  0.10453049,  0.11212737])\n",
      "Now processing:  0.9 0.0 0.1 0.0\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.878487\n",
      "         Iterations: 5\n",
      "         Function evaluations: 630\n",
      "   direc: array([[ 1.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  1.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  1.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  1.]])\n",
      "     fun: -0.8784867328319439\n",
      " message: 'Optimization terminated successfully.'\n",
      "    nfev: 630\n",
      "     nit: 5\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([ 0.62376208,  0.4276076 ,  0.1       ,  0.11513267,  0.55891051])\n"
     ]
    }
   ],
   "source": [
    "#lower and upper bound for variables pitch factor, energy factor, length factor\n",
    "bounds=[ [0,1.0], [0,1.0],[0.1,0.5], [0.1,0.5], [0.1,1.0]]\n",
    "\n",
    "#construct the bounds in the form of constraints\n",
    "cons = []\n",
    "for factor in range(len(bounds)):\n",
    "    lower, upper = bounds[factor]\n",
    "    l = {'type': 'ineq',\n",
    "         'fun': lambda x, lb=lower, i=factor: x[i] - lb}\n",
    "    u = {'type': 'ineq',\n",
    "         'fun': lambda x, ub=upper, i=factor: ub - x[i]}\n",
    "    cons.append(l)\n",
    "    cons.append(u)\n",
    "    \n",
    "print \"constraints: \", cons\n",
    "    \n",
    "initial_val = [0.95, 0.95, 0.3, 0.3, 0.5]\n",
    "\n",
    "# sample cover speech and code book waveforms\n",
    "base_path = \"/audio_samples/Harvard_Sentences_Short/\"\n",
    "cover_audio_list = [os.getcwd() + base_path + filename for filename in os.listdir(os.getcwd() + base_path)]\n",
    "\n",
    "w1 = \"speech_samples/french/pronunciation_fr_gemissait.mp3\"\n",
    "w2 = \"speech_samples/mandarin/pronunciation_zh_d.mp3\"\n",
    "\n",
    "params_dict = {}\n",
    "# acc, pitch, energy, length\n",
    "weights_list = [[0.7,0.1, 0.1, 0.1], [0.5,0.1, 0.3, 0.1], [0.3,0.2, 0.4, 0.1], [0.3,0.3, 0.3, 0.1], [0.1,0.4, 0.1, 0.4], [0.9,0.0, 0.1, 0.0]]\n",
    "\n",
    "for sys_weight, p_weight, e_weight, l_weight in weights_list:\n",
    "    print \"Now processing: \", sys_weight, p_weight, e_weight, l_weight\n",
    "    #opt = scipy.optimize.minimize(objective, initial_val, constraints=cons, tol=None, method=\"COBYLA\", options={'disp': True, 'rhobeg': 0.1})\n",
    "    opt = scipy.optimize.minimize(objective, initial_val, constraints=cons, tol=None, method=\"Powell\", options={'disp': True, 'xatol': 0.1, 'fatol': 0.1})\n",
    "    params_dict[(sys_weight, p_weight, e_weight, l_weight)] = opt\n",
    "    print opt\n",
    "\n",
    "pickle.dump( params_dict, open( \"powell_results_params_expanded_6-5-17.pkl\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check accuracy on dataset with optimized parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dataset_test(waveform_list):\n",
    "    results = {'conv':{}, 'bit': {}}\n",
    "    \n",
    "    # male - 1, female - 0\n",
    "    results_params = pickle.load(open(\"powell_results_params_expanded_6-5-17.pkl\", \"rb\"))\n",
    "    \n",
    "    \n",
    "    #paths_to_source = [\"audio_samples/woman2_orig.wav\"]#, \"audio_samples/man2_orig.wav\"]\n",
    "    base_path = \"/audio_samples/Harvard_Sentences_Short/\"\n",
    "    paths_to_source = [os.getcwd() + base_path + filename for filename in os.listdir(os.getcwd() + base_path)]\n",
    "    \n",
    "    w1 = waveform_list[0]\n",
    "    w2 = waveform_list[1]\n",
    "    \n",
    "\n",
    "    for p in paths_to_source:\n",
    "        print \"Currently processing: \", p\n",
    "        \n",
    "        for ws in results_params.keys():\n",
    "            [p0, p1, e0, e1, l] = results_params[ws]['x']\n",
    "            #print p0, p1, e0, e1, l\n",
    "\n",
    "            E2 = Embed(p, [w1, w2], [0,1], [0,1,0,1,0])\n",
    "\n",
    "            # Fix the truncation and energy values\n",
    "            E2.truncate(l, idx_list=[0,1])\n",
    "            E2.energy(e0, idx_list=[0])\n",
    "            E2.energy(e1, idx_list=[1])\n",
    "            E2.pitch_shift(p0 * -15.0, idx_list=[0])\n",
    "            E2.pitch_shift(p1 * -15.0, idx_list=[1])\n",
    "\n",
    "            embed2, num_total_digits = E2.get_embedded_audio(plot=False)\n",
    "            d_embed2, sr = compress_and_decompress(embed2, \"compression_samples/\", plot=False)\n",
    "\n",
    "            # get the timeseries of the the original waveforms and recover\n",
    "            wf = E2.get_data_timeseries()\n",
    "            R2 = Recover(d_embed2, wf, [0,1], [0,1,0,1,0], num_total_digits)\n",
    "            final_sequence2 = R2.get_bit_sequence(thres=0.85, plot=False)\n",
    "            bit_acc = R2.get_recovery_estimate(final_sequence2, conv=False)\n",
    "            conv_acc = R2.get_recovery_estimate(final_sequence2, conv=True)\n",
    "\n",
    "            # results metrics per speech sample\n",
    "            metadata = str(p)\n",
    "            try:\n",
    "                results['conv'][ws] += conv_acc / float(len(paths_to_source))\n",
    "                results['bit'][ws] += bit_acc / float(len(paths_to_source))\n",
    "            except:\n",
    "                results['conv'][ws] = conv_acc / float(len(paths_to_source))\n",
    "                results['bit'][ws] = bit_acc / float(len(paths_to_source))\n",
    "                \n",
    "            print ws, bit_acc\n",
    "            \n",
    "                    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently processing:  /home/ishwarya/Documents/math_modeling/AMR-Data-Embedding/audio_samples/Harvard_Sentences_Short/CHM11_05-05.wav\n",
      "(0.3, 0.2, 0.4, 0.1) 1.0\n",
      "(0.7, 0.1, 0.1, 0.1) 1.0\n",
      "(0.3, 0.3, 0.3, 0.1) 1.0\n",
      "(0.1, 0.4, 0.1, 0.4) 0.545454545455\n",
      "(0.9, 0.0, 0.1, 0.0) 1.0\n",
      "(0.5, 0.1, 0.3, 0.1) 1.0\n",
      "Currently processing:  /home/ishwarya/Documents/math_modeling/AMR-Data-Embedding/audio_samples/Harvard_Sentences_Short/CHM08_13-03.wav\n",
      "(0.3, 0.2, 0.4, 0.1) 1.0\n",
      "(0.7, 0.1, 0.1, 0.1) 1.0\n",
      "(0.3, 0.3, 0.3, 0.1) 1.0\n",
      "(0.1, 0.4, 0.1, 0.4) 0.619047619048\n",
      "(0.9, 0.0, 0.1, 0.0) 1.0\n",
      "(0.5, 0.1, 0.3, 0.1) 1.0\n",
      "Currently processing:  /home/ishwarya/Documents/math_modeling/AMR-Data-Embedding/audio_samples/Harvard_Sentences_Short/CHM06_06-01.wav\n",
      "(0.3, 0.2, 0.4, 0.1) 1.0\n",
      "(0.7, 0.1, 0.1, 0.1) 1.0\n",
      "(0.3, 0.3, 0.3, 0.1) 1.0\n",
      "(0.1, 0.4, 0.1, 0.4) 0.7\n",
      "(0.9, 0.0, 0.1, 0.0) 1.0\n",
      "(0.5, 0.1, 0.3, 0.1) 1.0\n",
      "Currently processing:  /home/ishwarya/Documents/math_modeling/AMR-Data-Embedding/audio_samples/Harvard_Sentences_Short/CHF04_10-09.wav\n",
      "(0.3, 0.2, 0.4, 0.1) 1.0\n",
      "(0.7, 0.1, 0.1, 0.1) 1.0\n",
      "(0.3, 0.3, 0.3, 0.1) 1.0\n",
      "(0.1, 0.4, 0.1, 0.4) 0.578947368421\n",
      "(0.9, 0.0, 0.1, 0.0) 1.0\n",
      "(0.5, 0.1, 0.3, 0.1) 1.0\n",
      "Currently processing:  /home/ishwarya/Documents/math_modeling/AMR-Data-Embedding/audio_samples/Harvard_Sentences_Short/CHM01_04-02.wav\n",
      "(0.3, 0.2, 0.4, 0.1) 1.0\n",
      "(0.7, 0.1, 0.1, 0.1) 1.0\n",
      "(0.3, 0.3, 0.3, 0.1) 1.0\n",
      "(0.1, 0.4, 0.1, 0.4) 0.631578947368\n",
      "(0.9, 0.0, 0.1, 0.0) 1.0\n",
      "(0.5, 0.1, 0.3, 0.1) 1.0\n",
      "Currently processing:  /home/ishwarya/Documents/math_modeling/AMR-Data-Embedding/audio_samples/Harvard_Sentences_Short/CHF10_02-06.wav\n",
      "(0.3, 0.2, 0.4, 0.1) 1.0\n",
      "(0.7, 0.1, 0.1, 0.1) 1.0\n",
      "(0.3, 0.3, 0.3, 0.1) 1.0\n",
      "(0.1, 0.4, 0.1, 0.4) 0.666666666667\n",
      "(0.9, 0.0, 0.1, 0.0) 1.0\n",
      "(0.5, 0.1, 0.3, 0.1) 1.0\n",
      "Currently processing:  /home/ishwarya/Documents/math_modeling/AMR-Data-Embedding/audio_samples/Harvard_Sentences_Short/CHF03_02-01.wav\n",
      "(0.3, 0.2, 0.4, 0.1) 1.0\n",
      "(0.7, 0.1, 0.1, 0.1) 1.0\n",
      "(0.3, 0.3, 0.3, 0.1) 1.0\n",
      "(0.1, 0.4, 0.1, 0.4) 0.555555555556\n",
      "(0.9, 0.0, 0.1, 0.0) 1.0\n",
      "(0.5, 0.1, 0.3, 0.1) 1.0\n",
      "Currently processing:  /home/ishwarya/Documents/math_modeling/AMR-Data-Embedding/audio_samples/Harvard_Sentences_Short/CHF06_34-01.wav\n",
      "(0.3, 0.2, 0.4, 0.1) 1.0\n",
      "(0.7, 0.1, 0.1, 0.1) 1.0\n",
      "(0.3, 0.3, 0.3, 0.1) 1.0\n",
      "(0.1, 0.4, 0.1, 0.4) 0.4\n",
      "(0.9, 0.0, 0.1, 0.0) 1.0\n",
      "(0.5, 0.1, 0.3, 0.1) 1.0\n",
      "Currently processing:  /home/ishwarya/Documents/math_modeling/AMR-Data-Embedding/audio_samples/Harvard_Sentences_Short/CHF07_13-01.wav\n",
      "(0.3, 0.2, 0.4, 0.1) 1.0\n",
      "(0.7, 0.1, 0.1, 0.1) 1.0\n",
      "(0.3, 0.3, 0.3, 0.1) 1.0\n",
      "(0.1, 0.4, 0.1, 0.4) 0.666666666667\n",
      "(0.9, 0.0, 0.1, 0.0) 1.0\n",
      "(0.5, 0.1, 0.3, 0.1) 1.0\n",
      "Currently processing:  /home/ishwarya/Documents/math_modeling/AMR-Data-Embedding/audio_samples/Harvard_Sentences_Short/CHM02_06-09.wav\n",
      "(0.3, 0.2, 0.4, 0.1) 1.0\n",
      "(0.7, 0.1, 0.1, 0.1) 1.0\n",
      "(0.3, 0.3, 0.3, 0.1) 1.0\n",
      "(0.1, 0.4, 0.1, 0.4) 0.56\n",
      "(0.9, 0.0, 0.1, 0.0) 1.0\n",
      "(0.5, 0.1, 0.3, 0.1) 1.0\n"
     ]
    }
   ],
   "source": [
    "results = dataset_test([\"speech_samples/french/pronunciation_fr_gemissait.mp3\",\"speech_samples/mandarin/pronunciation_zh_d.mp3\"])\n",
    "pickle.dump( results, open( \"accuracy_test_expanded_powell_hvd_6-5-17.pkl\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
